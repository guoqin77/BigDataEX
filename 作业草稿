 # MapReduce  预习报告

## 1 什么是MapReduce?

### （1） MapReduce是一种编程模型，是面向大数据并行处理的计算模型、框架和平台。
### （2）MapReduce是一个基于集群的高性能并行计算平台。
可以使用普通服务器构成一个包含数十、数百、甚至数千个节点的分布式和并行计算集群。
### （3）MapReduce是一个并行计算与运行的软件框架。
它提供了一个庞大但设计精良的并行计算软件框架，能自动划分计算数据和计算任务，自动完成计算任务的并行化处理，实现在集群节点上自动分配和执行任务并收集计算结果，将数据分布存储、数据通信、容错处理等并行计算涉及到的很多系统底层的复杂实现细节交由系统负责处理，大大减少了软件开发人员的负担。
### （4）MapReduce是一个并行程序设计模型与方法。
它提供了一种简便的并行程序设计方法，用Map和Reduce两个函数编程实现基本的并行计算任务，提供了抽象的操作和并行编程接口，以简单方便地完成大规模数据的编程和计算处理。


## 2  MapReduce的基本特点：

### （1）分布可靠，对数据集的操作分发给集群中的多个节点实现可靠性，每个节点周期性返回它完成的任务和最新的状态。
### （2）封装了实现细节，基于框架API编程，面向业务展开分布式编码。
### （3）提供跨语言编程的能力。

## 3 MapReduce 的工作流程大致可以分为5步
具体如下:

###  (1)  分片、格式化数据源

- 分片操作：

指的是将源文件划分为大小相等的小数据块( Hadoop 2.x 中默认 128MB )，也就是分片( split )，Hadoop 会为每一个分片构建一个 Map 任务，并由该任务运行自定义的 map() 函数，从而处理分片里的每一条记录;

- 格式化操作：

将划分好的分片( split )格式化为键值对<key,value>形式的数据，其中， key 代表偏移量， value 代表每一行内容。

### (2) 执行 MapTask

每个 Map 任务都有一个内存缓冲区(缓冲区大小 100MB )，输入的分片( split )数据经过 Map 任务处理后的中间结果会写入内存缓冲区中。
如果写入的数据达到内存缓冲的阈值( 80MB )，会启动一个线程将内存中的溢出数据写入磁盘，同时不影响 Map 中间结果继续写入缓冲区。
在溢写过程中， MapReduce 框架会对 key 进行排序，如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件。

### (3) 执行 Shuffle 过程

MapReduce 工作过程中， Map 阶段处理的数据如何传递给 Reduce 阶段，这是 MapReduce 框架中关键的一个过程，这个过程叫作 Shuffle。
Shuffle 会将 MapTask 输出的处理结果数据分发给 ReduceTask ，并在分发的过程中，对数据按 key 进行分区和排序。

### (4) 执行 ReduceTask

输入 ReduceTask 的数据流是<key, {value list}>形式，用户可以自定义 reduce()方法进行逻辑处理，最终以<key, value>的形式输出。

### (5) 写入文件
MapReduce 框架会自动把 ReduceTask 生成的<key, value>传入 OutputFormat 的 write 方法，实现文件的写入操作。

### MapReduce将作业的整个运行过程分为两个阶段：Map阶段Reduce阶段。

#### MapTask阶段
- Read 阶段： MapTask 通过用户编写的 RecordReader ，从输入的 InputSplit 中解析出一个个 key / value 。
- Map 阶段：将解析出的 key / value 交给用户编写的 Map ()函数处理，并产生一系列新的 key / value 。
- Collect 阶段：在用户编写的 map() 函数中，数据处理完成后，一般会调用 outputCollector.collect() 输出结果，在该函数内部，它会将生成的 key / value 分片(通过调用 partitioner )，并写入一个环形内存缓冲区中(该缓冲区默认大小是 100MB )。
- Spill 阶段：即“溢写”，当缓冲区快要溢出时(默认达到缓冲区大小的 80 %)，会在本地文件系统创建一个溢出文件，将该缓冲区的数据写入这个文件。
- Combine 阶段：当所有数据处理完成以后， MapTask 会对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。

#### ReduceTask阶段
- Copy 阶段： Reduce 会从各个 MapTask 上远程复制一片数据（每个 MapTask 传来的数据都是有序的），并针对某一片数据，如果其大小超过一定國值，则写到磁盘上，否则直接放到内存中
- Merge 阶段：在远程复制数据的同时， ReduceTask 会启动两个后台线程，分别对内存和磁盘上的文件进行合并，以防止内存使用过多或者磁盘文件过多。
- Sort 阶段：用户编写 reduce()方法输入数据是按 key 进行聚集的一组数据。
为了将 key 相同的数据聚在一起， Hadoop 采用了基于排序的策略。
由于各个 MapTask 已经实现对自己的处理结果进行了局部排序，因此， ReduceTask 只需对所有数据进行一次归并排序即可。
- Reduce 阶段：对排序后的键值对调用 reduce() 方法，键相等的键值对调用一次 reduce()方法，每次调用会产生零个或者多个键值对，最后把这些输出的键值对写入到 HDFS 中
- Write 阶段： reduce() 函数将计算结果写到 HDFS 上。


## 4 MapReduce技术特征
### （1）向“外”横向扩展，而非向“上”纵向扩展
### （2）失效被认为是常态
### （3）移动计算，把处理向数据迁移(数据本地性)
### （4）顺序处理数据、避免随机访问数据
### （5）推测执行
一个作业由若干个Map任务和Reduce任务构成，整个作业完成的时间取决于最慢的任务的完成时间。由于节点硬件、软件问题，某些任务可能运行很慢
采用推测执行机制，发现某个任务的运行速度远低于任务平均速度，会为慢的任务启动一个备份任务，同时运行。哪个先运行完，采用哪个结果。
### （6）平滑无缝的可扩展性
### （7）为应用开发隐藏系统底层细节

